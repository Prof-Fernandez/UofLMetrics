<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Limited Dependent Variables</title>
    <meta charset="utf-8" />
    <meta name="author" content="Jose M. Fernandez" />
    <script src="libs/header-attrs-2.26/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uol.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uol-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="extra.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Limited Dependent Variables
]
.subtitle[
## Censored and Truncated Data
]
.author[
### Jose M. Fernandez
]
.institute[
### University of Louisville
]
.date[
### 2020-7-4 (updated: 2024-03-17)
]

---

## Censored Data

In the world of data science sometimes data do not appear the way we would like.

One such case is when data are either _top coded_ or _bottom coded_.

For example, you may be interested in household income. You run to the American Community Survey only to find the following.

* Household earning less than $10,000 are given a lumped into one income category (i.e. _bottom coded_).
* Household earning more than $1,000,000 are given a lumped into the top income cateogry (i.e. _top coded_).

These variables are missing due to exogenous reasons.
---
![](https://www.researchgate.net/profile/Cheryl-Wachenheim/publication/23514232/figure/tbl1/AS:667777467686916@1536221963529/2-Income-levels-of-survey-participants.png)
We can use the midpoint for the in between values, but not the top or bottom categories.
---
## Censored Data

A second type of censored data is when the data are missing for endogenous reasons.

For example, a person's wage information is missing because they are not in the labor force. However, this does not mean that if we could magically put them in the labor force that their wage would be zero.

Simply, the person's __reservation wage__ is higher than the wage offers they are receiving.
---
![](https://libertystreeteconomics.newyorkfed.org/wp-content/uploads/sites/2/2022/12/LSE_2022_SCE-labor_kosar_ch1.png)
---
## Censored Data

A different example, consider you want to know the effect of High School GPA on College GPA. You will only observe a college GPA for people who get into college. Likewise, if you sample college students, then you will observe college GPA, but you will only observe the high school GPA of individuals who entered college.

AVG HS GPA given you went to college is 2.71. 

AVG HS GPA given you did not go to college is 2.04.
---
## Truncated Data

A third problem that can exist is that not only can you not observe the dependent variable, but you also cannot observed the explanatory variables.

In this case, if both the dependent and independent variables are censored due to a cutoff value, then we say the data are truncated.
---
## Censored Data

Therefore, we need three different types of models to deal with _exogenous_ missing data and _endogenous_ missing data.

Tobit - __exogenously__ censored dependent variable.

Truncated Regression - __exogenous__ censoring of both dependent and independent variables.

Sample Selection Model (Heckman Model) - __endogenously__ censored dependent variable
---
## Tobit

Suppose Y (wages) are subject to "top coding" (as is often observed in government data):
`$$Y=\left\{\begin{matrix}
y^* &amp; y^*&lt;c \\ 
c &amp; y^*&gt;c
\end{matrix}\right.$$`

We are interested in estimating the equation `$$Y=X\beta+u$$`

If we are willing to assume `\(u \rightarrow N(0,\sigma^2)\)`, then we can use the Tobit Model
---
## Tobit Density and Likelihood Function

The probability density of Y will resemble that of a normal distribution.
`$$f(y)=\left\{\begin{matrix}
\frac{1}{\sigma}\phi(\frac{y_i-X_i\beta}{\sigma}) &amp; y^*&lt;c \\ 
1-\Phi(\frac{c-X_i\beta}{\sigma}) &amp; y^*&gt;c
\end{matrix}\right.$$`

Log Likelihood Function `$$LL(\beta,\sigma)=\sum_{c&gt;y} \frac{1}{\sigma}\phi(\frac{y_i-X_i\beta}{\sigma})+\sum_{c&lt;y} 1-\Phi(\frac{c-X_i\beta}{\sigma})$$`
---
## Bottom Coding

The equation is very similar for the bottom coding situation.
__Bottom coding__ means we are censored from below.
`$$Y=\left\{\begin{matrix}
y^* &amp; y^*&gt;c \\ 
c &amp; y^*&lt;c
\end{matrix}\right.$$`
The likelihood function changes to capture this difference in bottom coding
Log Likelihood Function `$$LL(\beta,\sigma)=\sum_{c&lt;y} \frac{1}{\sigma}\phi(\frac{y_i-X_i'beta}{\sigma})+\sum_{c&gt;y} \Phi(\frac{c-X_i'beta}{\sigma})$$`
---
![](https://live.staticflickr.com/6227/6289592741_d2bd3ca766_z.jpg)
---
## The Expected Value of the Tobit model
Let's assume your y variable is bottom coded at zero. This means we only observe Y if Y&gt;0.

The unconditional expected value is of Y is
`$$E[Y_i]=\Phi(\frac{x_i \beta}{\sigma})(x_i \beta+\sigma *\lambda) \\ \lambda = \frac{\phi(x_i \beta/\sigma)}{\Phi(x_i \beta/\sigma)}$$`
If we condition on Y&gt;0, then the expected value simplifies to 

`$$E[Y_i|Y_i&gt;0,x]=x_i \beta+\sigma *\lambda \\ \lambda = \frac{\phi(x_i \beta/\sigma)}{\Phi(x_i \beta/\sigma)}$$`
The `\(\lambda\)` term is the Inverse Mills Ratio.

---
## Marginal Effects of Tobit Model

We can calculate the probability of Y&gt;0
`$$Pr(Y&gt;0)=\Phi(x_i \beta/\sigma) \\ \frac{d Pr(Y&gt;0)}{dx} = \frac{\beta}{\sigma}*\phi(x_i \beta/\sigma)$$`
Similarly, we can calculate the marginal effect of x on Y.
`$$\frac{d E[Y]}{dx} = \beta*\Phi(x_i \beta/\sigma)$$`

---
## Tobit Model in R

```r
library(AER)
library(stargazer)
data("Affairs")
fm.ols &lt;- lm(affairs ~ age + yearsmarried + religiousness + occupation
             + rating,  data = Affairs)
fm.tobit &lt;- tobit(affairs ~ age + yearsmarried + religiousness + occupation 
                  + rating,  data = Affairs)
fm.tobit2 &lt;- tobit(affairs ~ age + yearsmarried + religiousness + occupation 
                   + rating,  right = 4, data = Affairs)
stargazer(fm.ols,fm.tobit,fm.tobit2,type="html")
```
---
## Tobit Model in R 

&lt;table style="text-align:center"&gt;&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="3"&gt;affairs&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;OLS&lt;/em&gt;&lt;/td&gt;&lt;td colspan="2"&gt;&lt;em&gt;Tobit&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;age&lt;/td&gt;&lt;td&gt;-0.050&lt;sup&gt;b&lt;/sup&gt; (0.022)&lt;/td&gt;&lt;td&gt;-0.179&lt;sup&gt;b&lt;/sup&gt; (0.079)&lt;/td&gt;&lt;td&gt;-0.178&lt;sup&gt;b&lt;/sup&gt; (0.080)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;yearsmarried&lt;/td&gt;&lt;td&gt;0.162&lt;sup&gt;a&lt;/sup&gt; (0.037)&lt;/td&gt;&lt;td&gt;0.554&lt;sup&gt;a&lt;/sup&gt; (0.135)&lt;/td&gt;&lt;td&gt;0.532&lt;sup&gt;a&lt;/sup&gt; (0.141)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;religiousness&lt;/td&gt;&lt;td&gt;-0.476&lt;sup&gt;a&lt;/sup&gt; (0.111)&lt;/td&gt;&lt;td&gt;-1.686&lt;sup&gt;a&lt;/sup&gt; (0.404)&lt;/td&gt;&lt;td&gt;-1.616&lt;sup&gt;a&lt;/sup&gt; (0.424)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;occupation&lt;/td&gt;&lt;td&gt;0.106 (0.071)&lt;/td&gt;&lt;td&gt;0.326 (0.254)&lt;/td&gt;&lt;td&gt;0.324 (0.254)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;rating&lt;/td&gt;&lt;td&gt;-0.712&lt;sup&gt;a&lt;/sup&gt; (0.118)&lt;/td&gt;&lt;td&gt;-2.285&lt;sup&gt;a&lt;/sup&gt; (0.408)&lt;/td&gt;&lt;td&gt;-2.207&lt;sup&gt;a&lt;/sup&gt; (0.450)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Constant&lt;/td&gt;&lt;td&gt;5.608&lt;sup&gt;a&lt;/sup&gt; (0.797)&lt;/td&gt;&lt;td&gt;8.174&lt;sup&gt;a&lt;/sup&gt; (2.741)&lt;/td&gt;&lt;td&gt;7.901&lt;sup&gt;a&lt;/sup&gt; (2.804)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
---
## Marginal effects with Tobit
Let's use the `censReg` package to estimate the tobit model and get marginal effects.

```r
library(censReg)
estResult &lt;- censReg( affairs ~ age + yearsmarried + religiousness + occupation + rating, data = Affairs )
margEff(estResult) %&gt;% kable()
```



|              |           x|
|:-------------|-----------:|
|age           | -0.04192089|
|yearsmarried  |  0.12953651|
|religiousness | -0.39417189|
|occupation    |  0.07621840|
|rating        | -0.53413656|

---
class: center, inverse, middle
# Truncated Regression
---
## Truncated Regression

Truncated data differ from censored data in that we only observe y __and__ x if y is above (below) a certain cutoff. In censored data, we always observed x.

Example: Hausman and Wise's analysis of the New Jersey negative income tax experiment (Truncated Regression)

Goal: Estimate earnings function for low income individuals

Truncation: Individuals with earnings greater than 1.5 poverty level were excluded from the sample.

Two types of inference:

1. Inference about entire population in presence of truncation
2. Inference about sub-population observed
---
## Truncated Regression Model
`$$y_i=x_i'\beta+e_i, i=1, ..., n$$`
where the error term `\(e_i \rightarrow N(0,\sigma^2)\)`

Truncation from below: observe `\(y_i\)` and `\(x_i\)` if `\(y_i&gt;c\)`

Truncation from above: observe `\(y_i\)` and `\(x_i\)` if `\(y_i&lt;c\)`
---
## Truncated Normal Distribution
Let X be a normally distributed random variable with mean `\(\mu\)` and variance `\(\sigma^2\)`. Also, let there be a cutoff constant `\(c\)`.

Then we can write the probability density function of X to be 
`$$\begin{align*}f(X|X&gt;c) &amp;= \frac{f(x)}{Pr(X&gt;c)}=\frac{f(x)}{1-F(c)} \\ \\&amp;= \frac{\frac{1}{\sigma}\phi\frac{x-\mu}{\sigma}}{1-\Phi(\frac{c-\mu}{\sigma})}\end{align*}$$`
---
## Truncated Normal Distribution
The mean and variance are given by 
`$$\begin{align*}E[X|X&gt;c] &amp;= \mu+\sigma \lambda(\frac{c-\mu}{\sigma}) \\ var(X|X&gt;c) &amp;= \sigma^2(1-\delta(\frac{c-\mu}{\sigma})) \end{align*}$$`

where `\(\lambda(z)=\frac{\phi(z)}{1-\Phi(z)}\)` = Inverse Mills Ratio 

and `\(\delta(z)=\lambda(z)(\lambda(z)-z),\,0&lt;\delta(z)&lt;1\)`


---
## Truncated Normal Distribution

Consequences of not accounting for the truncation is that you will overstate the mean and understate the variance. __WHY?__

We are throwing out lower values pushing the mean up.

We are throwing out values from the extreme part of the distribution, which means we have less variation in the remaining data.

---
## Truncated Normal Distribution

![](truncnorm.png)

---
## Estimate of Truncated Normal
Simply using Ordinary Least Squares will result in a bias.

Instead, we use maximum likelihood. We can correct for the missing data by dividing the probability density function by the Pr(y&gt;c).

`$$f(y|y&gt;c) =\frac{\frac{1}{\sigma}\phi\frac{y-x'\beta}{\sigma}}{1-\Phi(\frac{c-x'\beta}{\sigma})}$$`
Notice that `\(\int_c^\infty f(y|y&gt;c) dy=1\)`

Likelihood function `$$L(\beta,\sigma^2|x,y)=\prod_i^n \frac{\frac{1}{\sigma}\phi\frac{y-x'\beta}{\sigma}}{1-\Phi(\frac{c-x'\beta}{\sigma})}$$`
---
## Truncated Regression in R

```r
########################
## Artificial example ##
########################
## simulate a data.frame
set.seed(1071)
n &lt;- 10000
sigma &lt;- 4
alpha &lt;- 2
beta &lt;- 1
x &lt;- rnorm(n, mean = 0, sd = 2)
eps &lt;- rnorm(n, sd = sigma)
y &lt;- alpha + beta * x + eps
d &lt;- data.frame(y = y, x = x)
```
---
## Truncated Regression in R

```r
library(truncreg) # Truncated Regression package
## truncated response
d$yt &lt;- ifelse(d$y &gt; 1, d$y, NA)
## compare estimates for full/truncated/censored/threshold response
fm_full &lt;- lm(y ~ x, data = d)
fm_ols &lt;- lm(yt ~ x, data = d)
fm_trunc &lt;- truncreg(yt ~ x, data = d, point = 1, direction = "left")
```
---
## OLS vs Truncreg

&lt;table style="text-align:center"&gt;&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="3"&gt;&lt;em&gt;Dependent variable:&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td colspan="3" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;Full Data&lt;/td&gt;&lt;td colspan="2"&gt;Truncated&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;OLS&lt;/td&gt;&lt;td&gt;OLS&lt;/td&gt;&lt;td&gt;Trunc. Reg.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;x&lt;/td&gt;&lt;td&gt;0.983&lt;sup&gt;a&lt;/sup&gt; (0.020)&lt;/td&gt;&lt;td&gt;0.462&lt;sup&gt;a&lt;/sup&gt; (0.019)&lt;/td&gt;&lt;td&gt;0.982&lt;sup&gt;a&lt;/sup&gt; (0.046)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Constant&lt;/td&gt;&lt;td&gt;2.022&lt;sup&gt;a&lt;/sup&gt; (0.040)&lt;/td&gt;&lt;td&gt;4.645&lt;sup&gt;a&lt;/sup&gt; (0.037)&lt;/td&gt;&lt;td&gt;1.964&lt;sup&gt;a&lt;/sup&gt; (0.177)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
---
## Truncated Regression: Histogram

```r
group1&lt;-rep("Normal",length(d$y))
group2&lt;-rep("Truncated",length(d$yt))
data_1&lt;-data.frame(c(d$y,d$yt),c(group1,group2))
names(data_1)&lt;-c("Y","groups")
library(ggplot2)
ggplot(data_1, aes(x=Y, fill=groups)) +
     geom_density(alpha=.3)
```
---
## Truncated Regression: Histogram
![](censored_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;
---
class: center, middle, inverse
# Endogenous Censoring
---
## Types of Sampling Bias
- Non-response Bias
- Survivorship Bias
- Attrition Bias
- Self-Selection Bias
- Undercoverage Bias
- Exclusion Bias
- Convenience Sampling
- Cherry picking

---
## Non-response Bias
![](https://images.prismic.io/sketchplanations/f2fdb7cb-f126-4897-ad78-4fd11c743172_SP+723+-+Sampling+bias.png?auto=format&amp;ixlib=react-9.0.3&amp;h=1887.6833845104059&amp;w=1600&amp;q=35&amp;dpr=3)

---
## Survivorship Bias
![](https://images.prismic.io/sketchplanations/ce000ac3-b8f1-4612-8c86-28f5d65442f7_SP+674+-+Survivorship+bias.png?auto=format&amp;ixlib=react-9.0.3&amp;h=1887.557603686636&amp;w=1600&amp;q=35&amp;dpr=3)

---
## Attrition Bias
![](https://images.prismic.io/sketchplanations/c24b9624-d973-4bf4-9c29-b248005ab56e_78697608699.jpg?auto=format&amp;ixlib=react-9.0.3&amp;h=1888.2591093117408&amp;w=1600&amp;q=35&amp;dpr=3)

---
## Heckman Model

The Heckman Model can be thought of as a two part model (but it can be done in one step)

Step 1. You estimate a probit/logit model that determines if the dependent variable is censored.

Step 2. Construct the Inverse Mills Ratio (corrects for sample selection)

Step 3. Run the regression including the Inverse Mills Ratio as an explanatory variable. 
---
## Heckman Model: Math

Consider the model
`$$\begin{align*}Y &amp;= X\beta +\sigma u \\
d &amp;=1(z'\gamma+v&gt;0) \end{align*}$$`

where z contains an instrumental variable not contained in X. The error terms `\(v\)` and `\(u\)` are assumed to be jointly distributed standard normal. `$$\binom{u}{v}\to N\left ( 0,\begin{bmatrix} 1 &amp; \rho \\ \rho &amp; 1 \end{bmatrix} \right )$$`
---
## Heckman Model: Math

We want to estimate the 

`$$\begin{align*}E[Y|X,d=1] &amp;= X\beta+\sigma E[u|d=1] \\
&amp;= X\beta+\sigma E[u|z'\gamma+v&gt;0]  \\
&amp;= X\beta+\sigma \rho \lambda(z'\gamma) \end{align*}$$`

where `\(\lambda(z\gamma)\)` is called the _Inverse Mills Ratio_ `$$\lambda(z\gamma)=\frac{\phi(z'\gamma)}{\Phi(z'\gamma)}$$`
Notice, this is the ratio between the _normal pdf_ and the _normal cdf_ of our probit coefficients with the person's X's. 
---
## Heckman Two Step

First, we estimate the decision equation to get our estimates of `\(\gamma\)`.

We use those estimates to construct `\(\lambda(z'\widehat{\gamma})\)`.

Then we estimate the level equation as `$$Y=X\beta+\alpha\lambda(z'\widehat{\gamma})+u$$`

If `\(\alpha=0\)`, then there is no sample selection problem.
---
## OLS versus Heckman

Now is a good time to think about how Heckman corrects OLS.

Let's restate the omitted variable bias (OVB) table, but using the correction factor as the OV. If x affects both the participation equation and the level equation, then we will have some sort of OVB.

Signs      | `\(Corr(x,\text{Mills Ratio})&gt;0\)` | `\(Corr(x,\text{Mills Ratio})&lt;0\)`
---------  | ------------------- | ------------------
`\(\alpha&gt;0\)`| Positive Bias       | Negative Bias
`\(\alpha&lt;0\)`| Negative Bias       | Positive Bias
---
## Simulation Example

```r
library(tidyverse)
library(sampleSelection)
set.seed(123456)
N = 10000
educ = sample(1:16, N, replace = TRUE)
age  = sample(18:64, N, replace = TRUE)
covmat = matrix(c(.46^2*4, .5*.46*2, .5*.46*2, 1), ncol = 2)
errors = mvtnorm::rmvnorm(N, sigma = covmat)
z = rnorm(N)
e = errors[, 1]
v = errors[, 2]
wearnl = 4.49 + .08 * educ + .12 * age + e
d_star = -1.5 + 0.15 * educ + 0.01 * age + 0.15 * z + v

observed_index  = d_star &gt; 0
d = data.frame(wearnl, educ, age, z, observed_index)
# lm based on full data
lm_all = lm(wearnl ~ educ + age, data=d)

# lm based on observed data
lm_obs = lm(wearnl ~ educ + age, data=d[observed_index,])
# Sample Selection model
selection_2step = selection(observed_index ~ educ + age + z, wearnl ~ educ + age, method = '2step')
stargazer::stargazer(lm_all,lm_obs,selection_2step, type = "html", font.size = "tiny", single.row = TRUE, star.char = c("c","b","a"), style = "qje", model.numbers = FALSE, omit.stat = c("rsq","f","adj.rsq","ser"))
```
---
## Simulation Example
&lt;small&gt;

&lt;table style="text-align:center"&gt;&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="3"&gt;wearnl&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="2"&gt;&lt;em&gt;OLS&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;selection&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;educ&lt;/td&gt;&lt;td&gt;0.080&lt;sup&gt;a&lt;/sup&gt; (0.002)&lt;/td&gt;&lt;td&gt;0.045&lt;sup&gt;a&lt;/sup&gt; (0.003)&lt;/td&gt;&lt;td&gt;0.076&lt;sup&gt;a&lt;/sup&gt; (0.010)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;age&lt;/td&gt;&lt;td&gt;0.121&lt;sup&gt;a&lt;/sup&gt; (0.001)&lt;/td&gt;&lt;td&gt;0.118&lt;sup&gt;a&lt;/sup&gt; (0.001)&lt;/td&gt;&lt;td&gt;0.120&lt;sup&gt;a&lt;/sup&gt; (0.001)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Constant&lt;/td&gt;&lt;td&gt;4.449&lt;sup&gt;a&lt;/sup&gt; (0.034)&lt;/td&gt;&lt;td&gt;5.191&lt;sup&gt;a&lt;/sup&gt; (0.050)&lt;/td&gt;&lt;td&gt;4.570&lt;sup&gt;a&lt;/sup&gt; (0.208)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;em&gt;N&lt;/em&gt;&lt;/td&gt;&lt;td&gt;10,000&lt;/td&gt;&lt;td&gt;5,540&lt;/td&gt;&lt;td&gt;10,000&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;rho&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;0.421&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Inverse Mills Ratio&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;0.380&lt;sup&gt;a&lt;/sup&gt; (0.123)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;em&gt;Notes:&lt;/em&gt;&lt;/td&gt;&lt;td colspan="3" style="text-align:right"&gt;&lt;sup&gt;***&lt;/sup&gt;Significant at the 1 percent level.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="3" style="text-align:right"&gt;&lt;sup&gt;**&lt;/sup&gt;Significant at the 5 percent level.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="3" style="text-align:right"&gt;&lt;sup&gt;*&lt;/sup&gt;Significant at the 10 percent level.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;/small&gt;
---
## Heckman Model in R

```r
library(sampleSelection)
data( Mroz87 )
Mroz87$kids  &lt;- ( Mroz87$kids5 + Mroz87$kids618 &gt; 0 )
# Two-step estimation
# heckit(first stage equation, second stage equation, data, method c("2step","ml"))
heck.m1 &lt;- heckit( lfp ~ age + I( age^2 ) + faminc + kids + educ,
   wage ~ exper + I( exper^2 ) + educ + city, Mroz87, method = "2step" ) 
# MLE Estimator
heck.m2 &lt;- heckit( lfp ~ age + I( age^2 ) + faminc + kids + educ,
   wage ~ exper + I( exper^2 ) + educ + city, Mroz87, method = "ml" ) 
# OLS Estimator
ols.m1 &lt;- lm(wage ~ exper + I( exper^2 ) + educ + city, Mroz87)
stargazer::stargazer(ols.m1,heck.m1,heck.m2,type="html", model.numbers = FALSE, font.size = "small", single.row = TRUE, star.char = c("c","b","a"), omit.table.layout = "sn")
```

---
&lt;small&gt;

&lt;table style="text-align:center"&gt;&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="3"&gt;wage&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;OLS&lt;/em&gt;&lt;/td&gt;&lt;td colspan="2"&gt;&lt;em&gt;Heckman&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;&lt;/em&gt;&lt;/td&gt;&lt;td colspan="2"&gt;&lt;em&gt;selection&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;exper&lt;/td&gt;&lt;td&gt;0.032 (0.062)&lt;/td&gt;&lt;td&gt;0.021 (0.062)&lt;/td&gt;&lt;td&gt;0.028 (0.062)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;I(exper2)&lt;/td&gt;&lt;td&gt;-0.0003 (0.002)&lt;/td&gt;&lt;td&gt;0.0001 (0.002)&lt;/td&gt;&lt;td&gt;-0.0001 (0.002)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;educ&lt;/td&gt;&lt;td&gt;0.481&lt;sup&gt;a&lt;/sup&gt; (0.067)&lt;/td&gt;&lt;td&gt;0.417&lt;sup&gt;a&lt;/sup&gt; (0.100)&lt;/td&gt;&lt;td&gt;0.457&lt;sup&gt;a&lt;/sup&gt; (0.073)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;city&lt;/td&gt;&lt;td&gt;0.449 (0.318)&lt;/td&gt;&lt;td&gt;0.444 (0.316)&lt;/td&gt;&lt;td&gt;0.447 (0.316)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Constant&lt;/td&gt;&lt;td&gt;-2.561&lt;sup&gt;a&lt;/sup&gt; (0.929)&lt;/td&gt;&lt;td&gt;-0.971 (2.059)&lt;/td&gt;&lt;td&gt;-1.963 (1.198)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;em&gt;N&lt;/em&gt;&lt;/td&gt;&lt;td&gt;428&lt;/td&gt;&lt;td&gt;753&lt;/td&gt;&lt;td&gt;753&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;rho&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;-0.343&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Inverse Mills Ratio&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;-1.098 (1.266)&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="4" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;em&gt;Notes:&lt;/em&gt;&lt;/td&gt;&lt;td colspan="3" style="text-align:right"&gt;&lt;sup&gt;***&lt;/sup&gt;Significant at the 1 percent level.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="3" style="text-align:right"&gt;&lt;sup&gt;**&lt;/sup&gt;Significant at the 5 percent level.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="3" style="text-align:right"&gt;&lt;sup&gt;*&lt;/sup&gt;Significant at the 10 percent level.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;/small&gt;
---
### The two step method 
We can do the two step method by brute force as well.


```r
first.stage&lt;-glm(lfp ~ age + I( age^2 ) 
                 + faminc + kids + educ , data=Mroz87, 
                 family=binomial(link = "probit"))
Mroz87$z1 &lt;- predict.glm(first.stage)
Mroz87$millsratio &lt;- dnorm(Mroz87$z1)/(pnorm(Mroz87$z1))
second.stage &lt;- lm(wage ~ exper + I( exper^2 ) 
                   + educ + city+millsratio, Mroz87)
```
---
&lt;small&gt;

&lt;table style="text-align:center"&gt;&lt;tr&gt;&lt;td colspan="3" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="2"&gt;&lt;em&gt;Dependent variable:&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td colspan="2" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="2"&gt;wage&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;OLS&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;Heckman&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;selection&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;(1)&lt;/td&gt;&lt;td&gt;(2)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="3" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;exper&lt;/td&gt;&lt;td&gt;0.021 (0.063)&lt;/td&gt;&lt;td&gt;0.021 (0.062)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;I(exper2)&lt;/td&gt;&lt;td&gt;0.0001 (0.002)&lt;/td&gt;&lt;td&gt;0.0001 (0.002)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;educ&lt;/td&gt;&lt;td&gt;0.417&lt;sup&gt;***&lt;/sup&gt; (0.099)&lt;/td&gt;&lt;td&gt;0.417&lt;sup&gt;***&lt;/sup&gt; (0.100)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;city&lt;/td&gt;&lt;td&gt;0.444 (0.318)&lt;/td&gt;&lt;td&gt;0.444 (0.316)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;millsratio&lt;/td&gt;&lt;td&gt;-1.098 (1.253)&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Constant&lt;/td&gt;&lt;td&gt;-0.971 (2.039)&lt;/td&gt;&lt;td&gt;-0.971 (2.059)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="3" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;Observations&lt;/td&gt;&lt;td&gt;428&lt;/td&gt;&lt;td&gt;753&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;R&lt;sup&gt;2&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;0.126&lt;/td&gt;&lt;td&gt;0.126&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Adjusted R&lt;sup&gt;2&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;0.116&lt;/td&gt;&lt;td&gt;0.116&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;rho&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;-0.343&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Inverse Mills Ratio&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;-1.098 (1.266)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Residual Std. Error&lt;/td&gt;&lt;td&gt;3.112 (df = 422)&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;F Statistic&lt;/td&gt;&lt;td&gt;12.208&lt;sup&gt;***&lt;/sup&gt; (df = 5; 422)&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="3" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;em&gt;Note:&lt;/em&gt;&lt;/td&gt;&lt;td colspan="2" style="text-align:right"&gt;&lt;sup&gt;*&lt;/sup&gt;p&lt;0.1; &lt;sup&gt;**&lt;/sup&gt;p&lt;0.05; &lt;sup&gt;***&lt;/sup&gt;p&lt;0.01&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;/small&gt;
---
## Summary
&lt;img src="summarypic.jpg" width="100%" style="display: block; margin: auto;" /&gt;
---
## Summary
&lt;img src="censored_pic.gif" width="100%" style="display: block; margin: auto;" /&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
