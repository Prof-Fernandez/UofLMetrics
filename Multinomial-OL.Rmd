---
title: "Limited Dependent Variables"
subtitle: "Multinomial Logit"
author: "Jose M. Fernandez"
institute: "University of Louisville"
date: "2020-7-4 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: [default, uol, uol-fonts, "extra.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: middle, center, inverse
# Modeling Consumer Choices
![](https://miro.medium.com/v2/resize:fit:753/0*UXAQquNLW9j0h2uo.png)
---
## Consumer Choices Modeling
![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*0YyZ-mCqrsoNtXSDGLeb6A.png){width=50% height=50%}
---
## Consumer Value

.pull-left[
Marketing and Consumer Behavior Research is all about affecting customer value.[You can read more here](https://hbr.org/2016/09/the-elements-of-value)

Favorite Quote about Marketing: "Marketing is the science of distracting the intelligent mind just long enough to extract money from it" Stephen Leacock, a Canadian humorist and economist. 
]


.pull-right[
![](consumer_quality.png){width=40% height=40%}
]

---
## Data Types
![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*80zoxrCIVgRF_YhgPK-CRg.png)
---
## Stated Preference Data

__Stated preference data__: These are data obtained by asking consumers to state their preferences directly, often through surveys or experiments. This type of data is based on hypothetical choices that consumers might make in different scenarios and can be used to explore how consumers value different attributes of a product or service. Stated preference data are generally easier and less expensive to collect than revealed preference data, but may be subject to biases and inaccuracies in how respondents perceive and report their preferences.

---
## Revealed preference data

__Revealed preference data__: These are data obtained by observing actual consumer behavior in the market, such as the products they purchase or the prices they pay. This type of data is based on actual choices that consumers make and is generally considered to be more reliable than stated preference data. However, revealed preference data can be difficult to collect and may be subject to confounding factors that make it hard to interpret.]


---
## Multi-choice data

Multi-choice data: This type of choice data involves asking respondents to choose among more than two options. For example, a survey question might ask which of several flavors of ice cream is the respondent’s favorite.

![](https://resources.pollfish.com/wp-content/uploads/2021/04/Screen-Shot-2021-04-02-at-1.40.49-PM.png)
---
## Ranked Choice Data

Ranked choice data: This type of choice data involves asking respondents to rank a set of options in order of preference. For example, a survey question might ask respondents to rank their top five choices for factors that are important at work. Or to be used in election [See a video at this link](https://youtu.be/gq7N2hmX9FI) or [see election data based on Ranked Choice](https://www.rcvresources.org/data-clearinghouse)

![](rc_work.png)

---
## Rating scale data
.pull-left[
Rating scale data: This type of choice data involves asking respondents to rate a set of options on a numerical scale. For example, a survey question might ask respondents to rate their level of satisfaction with a store on a scale from 1 to 5.]
.pull-right[
![](https://images.ctfassets.net/mmu68mmhtb17/5NjAIUArXG35AS6fHftWFd/f4d3407f2696591972735479b750fe56/Mental_health_pain_scale.png){width=50%,length=50%}
]
---
## Likert scale data
Likert scale data: This type of choice data involves asking respondents to rate their level of agreement or disagreement with a statement on a scale, typically ranging from “strongly agree” to “strongly disagree.”
![](https://chartexpo.com/blog/wp-content/uploads/2022/10/how-to-analyze-likert-scale-data-in-excel.jpg)
---
## Discrete choice Models

![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*sFPnBzwo-b-ivlpWcOhNgA.png)
---
class: middle, center, inverse
# Multinomial Logit
---
## Models with Multiple Choices
Examples of multinomial choice (polytomous) situations:

1. Choice of a laundry detergent: Tide, Cheer, Arm & Hammer, Wisk, etc. 
```{r out.width="50%", fig.align='center', echo=FALSE}
library(knitr)
include_graphics("https://reviewed-com-res.cloudinary.com/image/fetch/s--ILdgWui---/b_white,c_fill,cs_srgb,f_auto,fl_progressive.strip_profile,g_xy_center,q_auto,w_1200,x_2301,y_1292/https://reviewed-production.s3.amazonaws.com/1478026682000/Best-Detergent-TBRN-Hero.jpg")
```

2. Choice of a major: economics, marketing, management, finance or accounting.
3. Choices after graduating from high school: not going to college, going to a private 4-year college, a public 4 year-college, or a 2-year college. 
---
class: inverse, right
background-image: url("https://boardmember.com/wp-content/uploads/2019/03/AdobeStock_219846704-1024x678.jpeg")
## Models with Multiple Choices
.pull-right[
### Firms also have such multinomial choices
1. In which country to operate
2. Where to locate a store
3. Which CEO to hire
4. Modeling consumer behavior
]

---
## Multinomial Logit

The explanatory variable $x_i$ is __individual specific__, but does not change across alternatives. Example age of the individual.
	
The dependent variable is nominal

1. There are more than 2 choices

2. There is no meaningful ordering to them. 
  - Otherwise we would want to use that information (with an ordered probit or ordered logit)

---
## Multinomial Choice Probabilities

Recall, the logit probability is the case of two choices.

$$P_i=\frac{exp(\beta_{0i}+\beta_{1i}X_i)}{exp(\beta_{0i}+\beta_{1i}X_i)+ exp(\beta_{0k}+\beta_{1k}X_k)}$$
We typically normalize the betas for one of the choice in the case of logit (i.e. $\beta_k=0$)

$$P_i=\frac{exp(\beta_{0i}+\beta_{1i}X_i)}{1+exp(\beta_{0i}+\beta_{1i}X_i)}$$
---
## More than two choices
When we have more than two choices, the denominator changes to reflect all of the possible choices available. Here we have the probabilities for choice $i$ and choice $j$.

$$P_i=\frac{exp(\beta_{0i}+\beta_{1i}X_i)}{\sum_{k=1}^{K} exp(\beta_{0k}+\beta_{1k}X_k)}$$
$$P_j=\frac{exp(\beta_{0j}+\beta_{1j}X_j)}{\sum_{k=1}^{K} exp(\beta_{0k}+\beta_{1k}X_k)}$$
Relative probability choices $$P_i/P_j = \frac{exp(\beta_{0i}+\beta_{1i}X_i)}{exp(\beta_{0j}+\beta_{1j}X_j)}$$

---
## Relative Probabilities

We can only identify relative probabilities for each choice.

Similar to our discussion of dummy variables, we need to model our choices as relative to a base.

Just like we did in the logit case, we must set the base group by forcing one of the choices to have $\beta$'s equal to zero.

If we do this for choices $j$ and $i$, then the probabilities of selecting $j$ becomes $$P_j=\frac{1}{1+\sum_{k\neq j} exp(\beta_{0k}+\beta_{1k}X_k)}$$ $$P_i=\frac{exp(\beta_{0i}+\beta_{1i}X_i)}{1+\sum_{k\neq j} exp(\beta_{0k}+\beta_{1k}X_k)}$$

---
## IIA Property

* There is the implicit assumption in logit models that the odds between any pair of alternatives is independent of irrelevant alternatives (IIA)

One way to state the assumption

* If choice A is preferred to choice B out of the choice set {A,B}, then introducing a third alternative X, thus expanding that choice set to {A,B,X}, must not make B preferable to A. 

* which kind of makes sense.

---
## IIA Property

There is the implicit assumption in logit models that the odds between any pair of alternatives is independent of irrelevant alternatives (IIA)

In the case of the multinomial logit model, the IIA implies that adding another alternative or changing the characteristics of a third alternative must not affect the relative odds between the two alternatives considered. 

This is not realistic for many real life applications involving similar (substitute) alternatives. 

.pull-left[
```{r echo=FALSE, out.width="100%"}
include_graphics("http://www.ezbustoys.com/images/DB1T110.jpg")

```
]
.pull-right[
Red Bus / Blue Bus Paradox
]
---
## Red Bus/Blue Bus (McFadden 1974). 

Imagine commuters first face a decision between two modes of transportation: cars and red bus
 
Suppose that a consumer chooses between these two options with equal probability, 0.5, so that the odds ratio equals 1. 

Now add a third mode, blue bus. Assuming bus commuters do not care about the color of the bus (they are perfect substitutes), consumers are expected to choose between bus and car still with equal probability, so the probability of car is still 0.5, while the probabilities of each of the two bus types should go down to 0.25

However, this violates IIA: for the odds ratio between car and red bus to be preserved, the new probabilities must be: car 0.33; red bus 0.33; blue bus 0.33

The IIA axiom does not mix well with perfect substitutes.
---
## Alternatives to Multionomial Logit

The advantage of Multinomial Logit (and Logit for that matter) is that the probabilities have a closed form solution (i.e. a simple equation)

An alternative is to use Multinomial Probit. 

Advantage: NO IIA property!

Disadvantage: Computationally intensive once the number of choices is greater than 3.
---
## Types of Data formats for multinomial logit

There are often two types of datasets when encountering multinomial logit.

wide format: You observe only one observation by person. The row contains a dependent variable that is categorical and explanatory variables that could contain characteristics of each choice and characteristics of the chooser.

Example
```{r echo=TRUE, eval=FALSE}
data("Fishing", package = "mlogit")
head(Fishing)
```
---
## Types of Data formats for multinomial logit
Example
```{r echo=FALSE, eval=TRUE}
data("Fishing", package = "mlogit")
head(Fishing)
```
---
## Types of Data formats for multinomial logit

There are often two types of datasets when encountering multinomial logit.

long format: You observe a row for each choice and there is an id variable for each chooser. Each row contains a binary variable indicating if the person selected that choice. We also observe the choice's characteristics.

Example
```{r echo=TRUE, eval=FALSE}
data("TravelMode", package = "AER")
head(TravelMode)

```
---
## Types of Data formats for multinomial logit
Example
```{r echo=FALSE, eval=TRUE}
data("TravelMode", package = "AER")
head(TravelMode)
```
---
## Multinomial Logit: Three Types of models

There are three types of Multinomial Logit Model

1. Multinomial Logit: modeling choices based off of the person's characteristics.
2. Conditional Logit: modeling choices based off of the choice's characteristics.
3. Mixed Logit: modeling choices based off of both person's and choice's characteristics.

---
## Difference between Conditional and Multinomial Logit

Multinomial logit
$$U_{ij}=X_{i}\beta_j+e_{ij}$$
Conditional logit
$$U_{ij}=X_{ij}\beta+e_{ij}$$

Notice, the difference in the subscripts. Conditional logit does not estimate different $\beta$'s for each choice. Instead, there is one set of parameters, but the characteristics $X$ changes with each product.
---
## Important differences

Characteristics __CANNOT__ vary only by individual. If they do then they will fall out. 

$$Pr(Y_i=j)=\frac{exp(\beta_1 X_{ij}+\beta_2 Z_i)}{\sum_{k=1}^{K}exp(\beta_1 X_{ik}+\beta_2 Z_i) }$$

You can never estimate $\beta_2$ in this case.
---
## Proof

$$\begin{align*} Pr(Y_i=j) &=\frac{exp(\beta_1 X_{ij}+\beta_2 Z_i)}{\sum_{k=1}^{K}exp(\beta_1 X_{ik}+\beta_2 Z_i) } \\ \\
&=\frac{exp(\beta_1 X_{ij})exp(\beta_2 Z_i)}{\sum_{k=1}^{K}exp(\beta_1 X_{ik})exp(\beta_2 Z_i) } \\ \\
&=\frac{exp(\beta_1 X_{ij})exp(\beta_2 Z_i)}{exp(\beta_2 Z_i) \sum_{k=1}^{K}exp(\beta_1 X_{ik}) } \\ \\ 
&=\frac{exp(\beta_1 X_{ij})}{ \sum_{k=1}^{K}exp(\beta_1 X_{ik}) }\end{align*}$$
---
## Fixed Effect Logit

The conditional logit model can effectively removes certain fixed effects. 

Again, consider our previous example.
$$\begin{align*}Pr(Y_i=j) &=\frac{exp(\beta_1 X_{ij}+\beta_2 Z_i)}{\sum_{k=1}^{K}exp(\beta_1 X_{ik}+\beta_2 Z_i) } \\ \\
&=\frac{exp(\beta_1 X_{ij}+\alpha_i)}{\sum_{k=1}^{K}exp(\beta_1 X_{ik}+\alpha_i) }\end{align*}$$

__Warning__: As N grows large, the maximum likelihood routine is not well defined. This problem is called the incidental parameter problem and present in all non-linear models. In R, you can use the package _bife_ to reduce this problem.
---
## Mixed Logit

A mixed logit combines Conditional logit and multinomial logit

If you allow for random coefficients (unobserved heterogeneity also known as random effects), then the mixed logit model can overcome the IIA property.
---
## Conditional/Multinomial/Mixed Logit in R

We will use the mlogit package in R

```{r echo=TRUE, eval=FALSE}
library(mlogit)
data("Fishing", package = "mlogit")
Fish <- mlogit.data(Fishing, shape="wide", varying=2:9, choice="mode")
## a pure "conditional" model
m1<-mlogit(mode ~ price + catch, data = Fish)
## a pure "multinomial model"
m2<-mlogit(mode ~ 0 | income, data = Fish)
## which can also be estimated using multinom (package nnet)
#library("nnet")
#summary(multinom(mode ~ income, data = Fishing))
## a "mixed" model
m <- mlogit(mode ~ price+ catch | income, data = Fish)
p <- mlogit(mode ~ price+ catch | income, data = Fish, probit=TRUE)
stargazer::stargazer(m1,m2,m,p,type="html", dep.var.labels.include = FALSE ,column.labels = c("Conditional","Multinomial","Mixed","Probit"), font.size = "tiny", single.row = TRUE)
```
---
## Examples of Mixed Logit in R 
<font size=2>
```{r eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(mlogit)
data("Fishing", package = "mlogit")
Fish <- mlogit.data(Fishing, shape="wide", varying=2:9, choice="mode")
## a pure "conditional" model
m1<-mlogit(mode ~ price + catch, data = Fish)
## a pure "multinomial model"
m2<-mlogit(mode ~ 0 | income, data = Fish)
## which can also be estimated using multinom (package nnet)
#library("nnet")
#summary(multinom(mode ~ income, data = Fishing))
## a "mixed" model
m <- mlogit(mode ~ price+ catch | income, data = Fish)
p <- mlogit(mode ~ price+ catch | income, data = Fish, probit=TRUE)
stargazer::stargazer(m1,m2,m,p,type="html", dep.var.labels.include = FALSE ,column.labels = c("Conditional","Multinomial","Mixed","Probit"), font.size = "tiny", single.row = TRUE)
```
</font>
---
## Other advance routines

We cannot cover everything in this class. Some relevant models to learn in the future are 

- [Multinomial Logit with unobserved heterogeneity](https://jhelvy.github.io/logitr/articles/basic_usage.html)
  - 
- [Nested Logit](https://pdfs.semanticscholar.org/86fd/cf48d0fdf06b9c8efa1bf024a086e0e0b4aa.pdf)

---
## Other advance routines

- [Nested Logit](https://pdfs.semanticscholar.org/86fd/cf48d0fdf06b9c8efa1bf024a086e0e0b4aa.pdf)
![](https://www.researchgate.net/publication/27466428/figure/fig1/AS:669517051072521@1536636712910/Example-of-a-Nested-Binary-Logit-Model.png){width=50%,length=50%}
---
## Summary

* Multinomial choice models are used when the dependent variable represents a choice between several options
* Multinomial probit and multinomial logit are the most popular multinomial choice models
* If choice is between J + 1 options, both will have J equations
* Conditional logit is a special case of multinomial logit with only 1 equation
* Maximum likelihood estimation is the most common way of estimating all these models
* Explanatory variables can be characteristics of the options or the individuals (or both) and can lead to different models (so pay careful attention
* Care must be taken with interpretation of coefficients/marginal effects
