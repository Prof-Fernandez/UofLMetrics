---
title: "Linear Regression"
subtitle: "Difference in Differences"
author: "Jose M. Fernandez"
institute: "University of Louisville"
date: "2020-7-4 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: [default, uol, uol-fonts, "extra.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: middle, center, inverse
# Difference in Differences

---
## An Alternative Approach

We saw previously that RCT's are the ideal empirical study.

When an RCT is unavailable, then provided we observe enough covariates to eliminate all forms of selection and omitted variable bias, we can use regression to estimate accurate causal effects.

---
## Alternative Strategies

But sometimes we find ourselves in a situation where an RCT is not feasible, and it is impossible to observe all the important ways in which the treated and control units differ.

In this case, there are three additional empirical strategies typically use:

  - Difference in Differences
  - Instrumental Variables
  - Regression Discontinuity
  
Today, we will look at dif-in-dif.

---
## Framework

Recall the potential outcome framework. When we estimate a treatment-control contrast what we get is:
$$E(Y|D=1)-E(Y|D=0)=\delta+E(Y_0|D=1)-E(Y_0|D=0)$$
Where $\delta$ is the ATE.

This equation says that the average of the treated group minus the average of the control group is the average treatment effect plus selection bias (AKA omitted variable bias in the regression framework).

---
## Parallel Trends

We will now explore another way to get rid of the selection bias (i.e. $E(Y_0|D=1)-E(Y_0|D=0)$)

Suppose we have data on the outcome variable for our treatment and control group from a previous period. Call this $Y_{pre}$.

Now suppose further that:
$$E(Y_0|D=1)-E(Y_{pre}|D=1)=E(Y_0|D=0)-E(Y_{pre}|D=0)$$
This equation says the _change in the treatment group_ is equal to the _change in the control group_ when neither group receives the __active__ treatment.

This assumption is known as the __parallel trends__ assumptions and is crucial for getting compelling estimates in the dif-in-dif framework.

---
## Parallel Trends

It says that if the treatment group had never been treated, the average change in the outcome variable would have been identical to the average change in the outcome variable for the control group.

How plausible this assumption is depends upon the given study you are examining.

For now, let's assume it is true, and see how this can help us kill the selection bias.

---
# Our first Causal Model:DiD

Difference in Differences (DiD): exploits natural experiments in observational data to obtain causal estimates.

Need items
- Random (or quasi random) assignment of treatment and control groups.
- A pre-period and a post-period for both groups.
- No sample selection bias.
- Must have parallel trends.

---
## DAG
```{r echo = FALSE, fig.align='center',out.width = "75%", fig.cap="Causal Pathway Illustration: Z (confounder) is the cause of both X (independent variable) and Y (dependent variable) and thus, obscures the relationship between X and Y."}

library(knitr)
include_graphics("https://miro.medium.com/max/1750/1*KiRkxO-fUCfXSkJMR0bDig.png")
```
---
## DiD

The DiD estimator is a version of the Fixed Effects Model can be used with both 

- repeated cross-sectional (easier to obtain)
- and panel data. (harder to obtain)

DiD is a combination of time-series difference (compares outcomes across pre-treatment and post-treatment periods) and cross-sectional difference (compares outcomes between treatment and control groups).

---
## Intuition
There are two equivalent strategies to think about the two “differences”:
```{r echo=FALSE, out.width="110%", fig.align= "center"}
include_graphics("https://miro.medium.com/max/1750/1*YYT04dz8Mn80Bw3zyvTG_g.png")
```

---
## Visually DID
Visually, the DiD is the difference between these two changes:
1. changes in outcomes from pre-treatment to post-treatment
2. changes in outcomes between treatment and control groups
```{r echo=FALSE, out.width="110%", fig.align= "center"}
include_graphics("https://miro.medium.com/max/1750/1*yyVOO-oWeSPlgblipljulg.png")
```
---
##Regression DiD
$$y_{it}=\beta_0+\beta_1 Treat_i+\beta_2 Post_t+\beta_3 Treat_i*Post_t+\gamma X_{it}+e_{it}$$
While it is possible to obtain the DiD estimator by calculating the means by hand, using a regression framework may be more advantageous as it:

- outputs standard errors for hypothesis testing

- can be easily extended to include multiple periods and groups

- allows the addition of covariates
---
## Treatment Effect
```{r echo=FALSE, out.width="110%", fig.align= "center"}
include_graphics("https://miro.medium.com/max/1750/1*wJItSwzDDFe-YW4C9BZ1cw.png")
```
---
## Interpreting the Coefficients
- $\beta_0$: Average value of y in the control group during the preperiod.
- $\beta_1$: Average change in y from the first to the second time period that is common to both groups

- $\beta_2$: Average difference in y between the two groups that is common in both time periods

- $\beta_3$: Average differential change in y from the first to the second time period of the treatment group relative to the control group
---
## The coefficients visually

```{r echo=FALSE, out.width="110%", fig.align= "center"}
include_graphics("https://miro.medium.com/max/1750/1*etuwZRKQ-0cCfFO5jkMftw.png")
```
---
## Difference in Differences: Animated

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.align='center'}
library(knitr)
include_graphics('mydif.gif')
```

---
## Difference in Differences: Differences in Means Example
```{r echo=FALSE, warnings = FALSE, message=FALSE, out.width="150%", fig.align='center'}
include_graphics('DIDtabular.png')
```

---
## Difference in Differences: Graphical Approach

$$\begin{align*}Y&= \beta_0 + \beta_1*[Time] + \beta_2*[Intervention] \\
&+ \beta_3*[Time*Intervention] + \beta_4*[Covariates]+\epsilon\end{align*}$$
```{r echo=FALSE, message=FALSE, warning=FALSE, out.width="70%", fig.align='center'}
include_graphics("DIDregression.png")
```

---
## Parallel Trend Assumption

The parallel trend assumption is the most critical of the above the four assumptions to ensure internal validity of DID models and is the hardest to fulfill. 

It requires that in the absence of treatment, the difference between the 'treatment' and 'control' group is constant over time. 

Although there is no statistical test for this assumption, visual inspection is useful when you have observations over many time points. 

It has also been proposed that the smaller the time period tested, the more likely the assumption is to hold. 

Violation of parallel trend assumption will lead to biased estimation of the causal effect.

---
## Parralel Trend Assumption: Met

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width="80%",fig.align='center'}
include_graphics("ParallelTrend.png")
```

---
## Parralel Trend Assumption: Violated

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width="80%",fig.align='center'}
include_graphics("violationparallel.png")
```
---
## Generalized DiD

We can generalize the DiD model for multiple time periods.
- Very useful for policy adoption as they tend to happened at different times

$$y_{it}=\beta_0+\alpha_i+\delta_t+\beta_3 d_{it}+\gamma X_{it}+e_{it}$$

- $\alpha_i$: Individual fixed effects that change across individuals (state-specific characteristics, individual’s gender, etc.)

- $\delta_t$: Time fixed effects that change across time (e.g. year dummies to allow intercept to vary across different years)

- $d_{it}$: dummy variable which equals 1 if the unit of observation is in the post-treatment period (in contrast to Pt equals 1 in the second time period)
---
## Threats to Validity

1. Parallel Trends Assumption is violated
  - Try a placebo treatment
  - Visually inspect pre-trends using an event study

2. Difference in composition
  - Covariates can mitigate this problem
  - The people you are examining should not change too much within their group.
  
3. Extrapolation
- Depending on the setting of interest, results may be unable to generalise to other populations or even a longer timeframe.
---
## Silly Example

.left-column[
Consider a chili cheese hotdog
1. What is the cheese effect?
2. What is the chili effect?
3. What is the chili * cheese effect?
]

.right-column[
```{r echo=FALSE, out.width="50%", fig.align= "center"}
include_graphics("https://pbs.twimg.com/media/EHW3qolWwAAc0c0?format=jpg&name=large")
```
]
---
## A simple example in R
```{r}
library(foreign)
mydata = read.dta("http://dss.princeton.edu/training/Panel101.dta")
mydata$y <- mydata$y/1000000000
# First, let's create a post time variable
mydata$time = ifelse(mydata$year >= 1994, 1, 0)
# Second, let's create a treated group
mydata$treated = ifelse(mydata$country == "E" |
mydata$country == "F" |
mydata$country == "G", 1, 0)
# Third, the interaction term
mydata$did = mydata$time * mydata$treated
```
---
### 5 ways to do DiD
I will show you a couple of different ways to run DiD in R.
```{r echo=TRUE, eval=FALSE}
library(plm) #panel linear model
library(lfe) #linear fixed effect model
library(fixest)
reg1<-lm(y~time+treated+did, data=mydata)
reg2<-lm(y~time*treated, data=mydata)
reg3<-plm(y~did, data = mydata, index = c("country","year"), effect = "twoways", model = "within") 
reg4 <-felm(y~did | country + year, data = mydata)
reg5 <-feols(y~did | country + year, data = mydata)
```
---
```{r echo=FALSE, results='asis', eval=TRUE, warning=FALSE, message=FALSE}
library(plm) #panel linear model
library(lfe) #linear fixed effect model
library(fixest)
reg1<-lm(y~time+treated+did, data=mydata)
reg2<-lm(y~time*treated, data=mydata)
reg3<-plm(y~did, data = mydata, index = c("country","year"), effect = "twoways", model = "within")
reg4 <-felm(y~did | country + year, data = mydata)
reg5 <-feols(y~did | country + year, data = mydata)
texreg::htmlreg(list(reg1,reg2,reg3,reg4,reg5),override.se = list(NULL,NULL,NULL,NULL,se(reg5,se = "standard")))
```
---
## Event Study

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(ggplot2)
reg6 <- feols(y~ i(treated,year,1994)|country + year, data = mydata)
coefplot(reg6)
```


---
## Dif-in-Dif in Practice

__Case study: who pays for mandated childbirth coverage?__

When the government mandates employers to provide benefits, who is really footing the bill? 

  - Is it the employer? 
  - Or is it the employee who pays for it indirectly in the form of a pay cut?
  
This analysis is first conducted by Jonathan Gruber in 1994, an MIT Professor who serves as the director of the Health Care Program at the National Bureau of Economic Research (NBER). To date, The Incidence of Mandated Benefits remains one of the most influential paper in healthcare economics. 

---
## Timeline

Understanding the timeline is important for identifying the causal effect:

Before 1978: there was limited health care coverage for childbirth.

1975-1979: a subset of states passed laws, mandating the health care coverage of childbirth.

Starting in 1978: federal legislation mandates the health care coverage of childbirth for all states.

---
## Difference-in-Differences Table

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width="75%",fig.align='center'}
include_graphics("dif1.png")
```

---
## The Legendary Triple Dif

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width="75%",fig.align='center'}
include_graphics("dif2.png")
```

---
## Dif-in-Dif in R - Manual Calculation

```{r message=FALSE, warning=FALSE}
require(foreign)
eitc<-read.dta("https://github.com/CausalReinforcer/Stata/raw/master/eitc.dta")
# Create two additional dummy variables to indicate before/after
# and treatment/control groups.

# the EITC went into effect in the year 1994
eitc$post93 = as.numeric(eitc$year >= 1994)

# The EITC only affects women with at least one child, so the
# treatment group will be all women with children.
eitc$anykids = as.numeric(eitc$children >= 1)

# Compute the four data points needed in the DID calculation:
a = sapply(subset(eitc, post93 == 0 & anykids == 0, select=work), mean)
b = sapply(subset(eitc, post93 == 0 & anykids == 1, select=work), mean)
c = sapply(subset(eitc, post93 == 1 & anykids == 0, select=work), mean)
d = sapply(subset(eitc, post93 == 1 & anykids == 1, select=work), mean)

# Compute the effect of the EITC on the employment of women with children:
(d-c)-(b-a)
```

---
## Dif-in-Dif in R - Regression

$$work=\beta_0+\delta_0posst93+\beta_1anykids+\delta_1(anykids*post93)+\epsilon$$
```{r warning=FALSE, message=FALSE}
reg1 = lm(work ~ post93 + anykids + post93*anykids, data = eitc)
summary(reg1)
```

---
## Create Plot

```{r eval=FALSE, warning=FALSE, message=FALSE}
# Take average value of 'work' by year, conditional on anykids
minfo = aggregate(eitc$work, list(eitc$year,eitc$anykids == 1), mean)
# rename column headings (variables)
names(minfo) = c("YR","Treatment","LFPR")

# Attach a new column with labels
minfo$Group[1:6] = "Single women, no children"
minfo$Group[7:12] = "Single women, children"
#minfo

require(ggplot2)	#package for creating nice plots

qplot(YR, LFPR, data=minfo, geom=c("point","line"), colour=Group,
xlab="Year", ylab="Labor Force Participation Rate")+geom_vline(xintercept = 1994)
```

---
## Create Plot

```{r echo=FALSE,fig.align='center', warning=FALSE, message=FALSE}
# Take average value of 'work' by year, conditional on anykids
minfo = aggregate(eitc$work, list(eitc$year,eitc$anykids == 1), mean)
# rename column headings (variables)
names(minfo) = c("YR","Treatment","LFPR")

# Attach a new column with labels
minfo$Group[1:6] = "Single women, no children"
minfo$Group[7:12] = "Single women, children"
#minfo

require(ggplot2)	#package for creating nice plots

qplot(YR, LFPR, data=minfo, geom=c("point","line"), colour=Group,
xlab="Year", ylab="Labor Force Participation Rate")+geom_vline(xintercept = 1994)
```

---
class: center, middle, inverse
# Strengths and Limitations

---
## Strengths

* Intuitive interpretation
* Can obtain causal effect using observational data if assumptions are met
* Can use either individual and group level data
* Comparison groups can start at different levels of the outcome. (DID focuses on change rather than absolute levels)
* Accounts for change/change due to factors other than intervention

---
## Limitations

* Requires baseline data & a non-intervention group
* Cannot use if intervention allocation determined by baseline outcome
* Cannot use if comparison groups have different outcome trend (Abadie 2005 has proposed solution)
* Cannot use if composition of groups pre/post change are not stable

---
## BEST PRACTICES
 
* Be sure outcome trends did not influence allocation of the treatment/intervention
* Acquire more data points before and after to test parallel trend assumption
* Use linear probability model to help with interpretability
* Be sure to examine composition of population in treatment/intervention and control groups before and after intervention
* Use robust standard errors to account for autocorrelation between pre/post in same individual
* Perform sub-analysis to see if intervention had similar/different effect on components of the outcome
