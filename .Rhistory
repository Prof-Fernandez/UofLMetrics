install.packages(c("stargazer", "texreg"))
data("cars")
stargazer::stargazer(cars,type="text", summary=TRUE)
stargazer::stargazer(cars,type="text", summary=TRUE, covariate.labels = c("Speed","Distance"))
library(readr)
lime_data <- read_csv("https://www.cdc.gov/lyme/resources/LD-Case-Counts-by-County-00-18.csv")
county_population <- read_csv("https://data.nber.org/census/popest/county_population.csv")
View(county_population)
View(county_population)
county_population<-complete.cases(county_population)
county_population <- read_csv("https://data.nber.org/census/popest/county_population.csv")
county_population <- county_population[ is.na(county_population$pop1994),]
View(lime_data)
View(lime_data)
install.packages("tidyverse")
library(tidyverse)
lime_data<-pivot_longer(lime_data, starts_with("Cases"), names_to = "year", values_to = "Cases")
county_population <- pivot_longer(county_population, starts_with("pop"), names_to = "year", values_to = "population")
View(lime_data)
View(county_population)
lime_data$county_fips <- lime_data$STCODE*1000+lime_data$CTYCODE
lime_data <- read_csv("https://www.cdc.gov/lyme/resources/LD-Case-Counts-by-County-00-18.csv")
county_population <- read_csv("https://data.nber.org/census/popest/county_population.csv")
county_population <- county_population[ is.na(county_population$pop1994),]
# Each row in these data represents a county
# This next step will make it county year.
library(tidyverse)
lime_data<-pivot_longer(lime_data, starts_with("Cases"), names_to = "year", names_prefix = "Cases", values_to = "Cases")
county_population <- pivot_longer(county_population, starts_with("pop"), names_prefix = "pop", names_to = "year", values_to = "population")
lime_data$county_fips <- lime_data$STCODE*1000+lime_data$CTYCODE
total <- merge(county_population,lime_data,by=c("county_fips","year")
)
View(total)
remotes::install_github('yihui/xaringan')
install.packages("remotes")
remotes::install_github('yihui/xaringan')
install.packages(c("DT", "leaflet"))
install.packages(c("ggdag", "kableExtra", "mlbench", "RefManageR", "svglite", "tidymodels", "truncnorm"))
install.packages("caret")
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(eval = TRUE,
echo = TRUE,
warning = FALSE,
message = FALSE,
cache = FALSE,
dev = "svglite",
fig.ext = ".svg")
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
theme_set(theme_minimal(20))
# tools
library(caret)
# some data
data(iris)
dataset <- iris
# create a list of 80% of the rows in the original dataset we can use for training
validation_index <- createDataPartition(dataset$Species, p=0.80, list=FALSE)
# select 20% of the data for validation
validation <- dataset[-validation_index,]
# use the remaining 80% of data to training and testing the models
dataset <- dataset[validation_index,]
head(dataset)
# summarize the class distribution
percentage <- prop.table(table(dataset$Species)) * 100
cbind(freq=table(dataset$Species), percentage=percentage)
summary(dataset)
# split input and output
x <- dataset[,1:4]
y <- dataset[,5]
# scatterplot matrix
featurePlot(x=x, y=y, plot="ellipse")
featurePlot(x,y,plot = "ellipse")
# split input and output
x <- dataset[,1:4]
y <- dataset[,5]
# scatterplot matrix
# boxplot for each attribute on one image
par(mfrow=c(1,4))
for(i in 1:4) {
boxplot(x[,i], main=names(iris)[i])
}
featurePlot(x=x, y=y, plot="ellipse")
# split input and output
x <- dataset[,1:4]
y <- dataset[,5]
# scatterplot matrix
# boxplot for each attribute on one image
par(mfrow=c(1,4))
for(i in 1:4) {
boxplot(x[,i], main=names(iris)[i])
}
# featurePlot(x=x, y=y, plot="ellipse")
install.packages("e1071")
# a) linear algorithms
set.seed(7)
fit.lda <- train(Species~., data=dataset, method="lda", metric=metric, trControl=control)
install.packages("caret", dependencies=c("Depends", "Suggests"))
install.packages("caret", dependencies = c("Depends", "Suggests"))
library(readxl)
covid_data <- read_excel("C:/Users/jmfern02.AD/Downloads/covid_data.xlsx")
View(covid_data)
save.image("C:/Users/jmfern02.AD/Downloads/covid_data.RData")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
load("C:/Users/jmfern02.AD/Downloads/covid_data.RData")
owid_covid_data <- covid_data
prdata <- owid_covid_data %>% filter(iso_code=="PRI")
library(forecast)
install.packages("forecast")
library(forecast)
View(prdata)
View(prdata)
cases<-ts(prdata$new_cases, frequency = 30, start = c(2020,3,28))
cases<-ts(prdata$new_cases, frequency = 365.25, start = c(2020,3,28))
cases<-ts(prdata$new_cases, frequency = 365.25, start = c(2020,88))
plot(prdata$new_cases, type = 'l', ylab = "Daily New Cases")
cases<-ts(prdata$new_cases, frequency = 365.25, start = c(2020,3,28))
plot(cases)
decompose(cases)
decompose(prdata$new_cases)
cases
x<-decompose(cases, type = "additive")
cases<-ts(prdata$new_cases, frequency = 365, start = c(2020,3,28))
x<-decompose(cases, type = "additive")
cases<-ts(prdata$new_cases, frequency = 365/7, start = c(2020,3,28))
x<-decompose(cases, type = "additive")
plot(x)
cases<-ts(prdata$new_cases, frequency = 365/7, start = c(2020,3,28), deltat = 1/7)
x<-decompose(cases, type = "additive")
plot(x)
cases<-ts(prdata$new_cases, frequency = 365, start = c(2020,3,28), deltat = 1/7)
x<-decompose(cases, type = "additive")
cases<-ts(prdata$new_cases, frequency = 365/7, start = c(2020,3,28), deltat = 1/7)
x<-decompose(cases, type = "additive")
plot(x)
library(tseries)
x1<-auto.arima(cases, stationary = TRUE)
View(x1)
cases<-ts(prdata$new_cases, frequency = 365, deltat = 1/365, start = c(2020))
plot(cases)
cases<-ts(prdata$new_cases, frequency = 365, deltat = 1/365, start = c(2020,1/7))
plot(cases)
cases<-ts(prdata$new_cases, frequency = 365, deltat = 1/365, start = c(2020,3))
plot(cases)
cases<-ts(prdata$new_cases, frequency = 365, deltat = 1/365, start = c(2020+88/365))
plot(cases)
data("ChickWeight")
data("Seatbelts")
View(ChickWeight)
rm(ChickWeight)
force(Seatbelts)
rm(Seatbelts)
data("mtcars")
head(mtcars)
table(mtcars$vs,mtcars$am)
table(factor(mtcars$vs),factor(mtcars$am))
table(factor(mtcars$vs),mtcars$am)
lm(factor(mtcars$vs)~mtcars$am)
lm(mtcars$vs~mtcars$am)
load("C:/Users/jmfern02.AD/Desktop/county_ucr_offenses_known_yearly_1960_2017.rda")
View(county_ucr_offenses_known_yearly_1960_2017)
View(county_ucr_offenses_known_yearly_1960_2017)
library(tidyverse)
ky_off<-county_ucr_offenses_known_yearly_1960_2017 %>% filter(state_ab=="KY")
ky_off<-county_ucr_offenses_known_yearly_1960_2017 %>% ungroup %>% filter(state_ab=="KY")
ky_off<-county_ucr_offenses_known_yearly_1960_2017 %>% ungroup %>% filter(state_abb=="KY")
library(readr)
X315 <- read_csv("https://extranet.who.int/ncdsmicrodata/index.php/catalog/31/download/315")
View(X315)
View(X315)
library(readr)
ARG_2007 <- read_csv("https://extranet.who.int/ncdsmicrodata/index.php/catalog/31/download/315")
library(tidyverse)
ARG_2007_small <- ARG_2007 %>% select(Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q8,Q25,Q26)
names(ARG_2007_small)<-c(age,gender,grade,height,weight,hungry,fruit,veg,suicide_ideation,suicide_plan)
names(ARG_2007_small)<-c("age","gender","grade","height","weight","hungry","fruit","veg","suicide_ideation","suicide_plan")
source('C:/Users/jmfern02.AD/Downloads/lauren_example.R')
summary(reg1)
install.packages(c("actuar", "arrow", "backports", "bayestestR", "brio", "broom", "bssm", "candisc", "cli", "coin", "cpp11", "crayon", "crs", "dagitty", "dbplyr", "DescTools", "dfidx", "DiceOptim", "DoE.base", "dplyr", "emmeans", "Epi", "Factoshiny", "flextable", "forcats", "ftExtra", "furrr", "gamboostLSS", "gert", "ggthemes", "GLMMadaptive", "heatmaply", "heplots", "htmltools", "inum", "IRdisplay", "KFAS", "knitr", "ks", "Lahman", "libcoin", "mathjaxr", "matrixStats", "MCMCpack", "mdmb", "measures", "memoise", "merDeriv", "mice", "miceadds", "mitml", "mlbench", "mlr3", "mlt", "mondate", "multcomp", "paradox", "parsnip", "party", "partykit", "performance", "pixmap", "plm", "plotrix", "pracma", "quantreg", "R.devices", "randomForestSRC", "rappdirs", "Rcpp", "repr", "reprex", "rgdal", "ridge", "rms", "robustlmm", "RPostgres", "RSQLite", "shiny", "shinythemes", "shinyWidgets", "simputation", "spacetime", "spatstat.utils", "stabs", "stars", "systemfonts", "terra", "tibble", "tinytex", "tkrplot", "tmap", "TMB", "tweedie", "vcdExtra", "VIM", "withr"))
x <- 1:12
grouping <- rep(1:3, c(3,5,4))
d1<-data.frame[x,grouping]
d1<-data.frame(x,grouping)
d1
ave(x, grouping, FUN = mean)
ave(x, grouping, FUN = sum)
ave(x, FUN = sum)
ave(x, FUN = sum)-ave(x,grouping, FUN = sum)
(ave(x, FUN = sum)-ave(x,grouping, FUN = sum))/ave(x,grouping, FUN = length())
(ave(x, FUN = sum)-ave(x,grouping, FUN = sum))/(ave(x, FUN = function (b) length(b))-ave(x,grouping, FUN = function(b) length(b)))
(ave(x, FUN = sum)-ave(x,grouping, FUN = sum))
/(ave(x, FUN = function (b) length(b))-ave(x,grouping, FUN = function(b) length(b)))
install.packages("optmatch")
install.packages("devtools")
devtools::install_git(
"https://github.com/ccolonescu/PoEdata")
install.packages("mlogit")
library(mlogit)
data("Fishing", package = "mlogit")
Fish <- mlogit.data(Fishing, varying = c(2:9), shape = "wide", choice = "mode",id="chid")
Fish <- mlogit.data(Fishing, varying = c(2:9), shape = "wide", choice = "mode",id="chid")
View(Fishing)
Fish <- mlogit.data(Fishing, shape="wide", varying=2:9, choice="mode")
?stargazer
suppressPackageStartupMessages(library(AER,quietly=TRUE,warn.conflicts=FALSE))
library(ggplot2,quietly=TRUE,warn.conflicts=FALSE)
data("CASchools")
CASchools$str=CASchools$students/CASchools$teachers
CASchools$testscr=(CASchools$read+CASchools$math)/2
qplot(x=str, y=testscr, data=CASchools, geom="point",
xlab="Student/Teacher Ratio", ylab="Test Scores")
knitr::opts_chunk$set(echo = TRUE)
library(stargazer)
library(AER)
data("CASchools")
summary(CASchools)
library(haven)
speeding_tickets_text <- read_dta("C:/Users/jmfern02.AD/Downloads/SpeedingTicketsData/Ch07.Ex5.SpeedingTicketsData/speeding_tickets_text.dta")
View(speeding_tickets_text)
Fines <- speeding_tickets_text$Amount
Fines[is.na(Fines)]<-0
hist(Fines)
suppressPackageStartupMessages(library(AER,quietly=TRUE,warn.conflicts=FALSE))
library(ggplot2,quietly=TRUE,warn.conflicts=FALSE)
data("CASchools")
CASchools$str=CASchools$students/CASchools$teachers
CASchools$testscr=(CASchools$read+CASchools$math)/2
qplot(x=str, y=testscr, data=CASchools, geom="point",
xlab="Student/Teacher Ratio", ylab="Test Scores")
reg1<-lm(math ~ income, data = CASchools)
reg2<-lm(math ~ income+expenditure, data = CASchools)
library(stargazer)
stargazer(reg1,reg2,type = "text")
summary(reg1)
z <- -1:.1:1
z <- seq(-3,3, by = .1)
z2 <- z[1:end-1]
z2 <- z[1:length(z)-1]
z1 <- z[2:length(z)]
# We will make some fake data
XA <- rnorm(1000)*10+20
XB <- rnorm(1000)*20+10
eA <- rnorm(1000)*5
eB <- rnorm(1000)*5
B <- 0.1
y_star <- (XA-XB)*B + eA - eB
y <- ifelse(y_star>0,1,0)
mean(y)
# We will make some fake data
XA <- rnorm(1000)*10+20
XB <- rnorm(1000)*20+10
eA <- rnorm(1000)*5
eB <- rnorm(1000)*5
B <- 0.2
y_star <- (XA-XB)*B + eA - eB
y <- ifelse(y_star>0,1,0)
mean(y)
# We will make some fake data
XA <- rnorm(1000)*10+20
XB <- rnorm(1000)*20+10
eA <- rnorm(1000)*5
eB <- rnorm(1000)*5
B <- 0.6
y_star <- (XA-XB)*B + eA - eB
y <- ifelse(y_star>0,1,0)
mean(y)
#Let's run a regression using both y_star and y
X = XA - XB # we can only identify relative effects
reg1 <-lm(y_star ~ X)
reg2 <- lm(y ~ X)
stargazer::stargazer(reg1,reg2, type = "html")
coeftest(reg2, vcov.=vcovHAC(fm1))
library(AER)
coeftest(reg2, vcov.=vcovHAC(fm1))
coeftest(reg2, vcov.=vcovHAC(reg2))
y_star_hat <- predict(reg1,X)
y_star_hat <- predict(reg1,as.data.frame(X))
y_hat <- predict(reg2,X)
y_star_hat <- predict(reg1,as.data.frame(X))
y_hat <- predict(reg2,as.data.frame(X))
y_star_hat_adj <- ifelse(y_star_hat>0,1,0)
mean(y_star_hat_adj)
mean(y_hat)
w<-c(rep(1,100))
x1<-1:1000
kronecker(w,x1)
x2<-kronecker(w,x1)
x2<-kronecker(x1,w)
# Let's create individual level data for a logit
X <- rnorm(100000)*5+20
e1 <- rnorm(100000)*20
x1<-1:1000
w<-c(rep(1,100))
x2<-kronecker(x1,w)
B <- 0.7
y_star <- X*B + e1
y <- ifelse(y_star>0,1,0)
mean(y)
# Let's create individual level data for a logit
X <- rnorm(100000)*5+20
e1 <- rnorm(100000)*20
x1<-1:1000
w<-c(rep(1,100))
x2<-kronecker(x1,w)
B <- 0.7
y_star <- X*B + e1
y <- ifelse(y_star>0,1,0)
mean(y)
mydata <- data.frame(y,X,x2)
mylogit1 <- glm(y ~ X, family = "binomial", data = mydata)
mylogit2 <- logitmfx(y~X, data = mydata)
library(mfx)
# Let's create individual level data for a logit
X <- rnorm(100000)*5+20
e1 <- rnorm(100000)*20
x1<-1:1000
w<-c(rep(1,100))
x2<-kronecker(x1,w)
B <- 0.7
y_star <- X*B + e1
y <- ifelse(y_star>0,1,0)
mean(y)
mydata <- data.frame(y,X,x2)
mylogit1 <- glm(y ~ X, family = "binomial", data = mydata)
mylogit2 <- logitmfx(y~X, data = mydata)
mydata_group<-aggregate(mydata[, 1:2],mydata$x2, mean)
mydata_group<-aggregate(mydata[, 1:2],list(mydata$x2), mean)
View(mydata_group)
View(mydata)
View(mydata)
View(mydata_group)
View(mydata_group)
# Let's create individual level data for a logit
X <- rnorm(100000)*5+20
e1 <- rnorm(100000)*20
x1<-1:1000
w<-c(rep(1,100))
x2<-kronecker(x1,w)
B <- 0.7
y_star <- X*B + e1
y <- ifelse(y_star>0,1,0)
mean(y)
mydata <- data.frame(y,X,x2)
mylogit1 <- glm(y ~ X, family = "binomial", data = mydata)
mylogit2 <- logitmfx(y~X, data = mydata)
mydata_group<-aggregate(mydata[, 1:2],list(mydata$x2), mean)
# now y is represented as a share
mydata_group$y2 <- log(mydata_group$y)-log(1-mydata_group$y)
mylogit3 <- lm(y2 ~ X, mydata_group)
```
# Let's create individual level data for a logit
X <- rnorm(100000)*5+20
e1 <- rnorm(100000)*20
x1<-1:1000
w<-c(rep(1,100))
x2<-kronecker(x1,w)
B <- 0.7
y_star <- X*B + e1
y <- ifelse(y_star>0,1,0)
mean(y)
mydata <- data.frame(y,X,x2)
mylogit1 <- glm(y ~ X, family = "binomial", data = mydata)
mylogit2 <- logitmfx(y~X, data = mydata)
mydata_group<-aggregate(mydata[, 1:2],list(mydata$x2), mean)
# now y is represented as a share
mydata_group$y2 <- log(mydata_group$y)-log(1-mydata_group$y)
mylogit3 <- lm(y2 ~ X, mydata_group)
stargazer::stargazer(mylogit1,mylogit2,mylogit3,type="text")
View(mylogit2)
View(mylogit2)
setwd("C:/Users/jmfern02.AD/OneDrive - University of Louisville/GitHub/UofLMetrics")
library(foreign)
dat <- read.dta("https://stats.idre.ucla.edu/stat/data/ologit.dta")
head(dat)
library(erer)
m_probit <- polr(apply ~ pared + public + gpa, data = dat, Hess=TRUE, method = "probit")
library(MASS)
library(erer)
m_probit <- polr(apply ~ pared + public + gpa, data = dat, Hess=TRUE, method = "probit")
m_logit <- polr(apply ~ pared + public + gpa, data = dat, Hess=TRUE, method = "logistic")
m1_probit<-ocME(m_probit,rev.dum = TRUE)
m1_logit<-ocME(m_logit,rev.dum = TRUE)
as.table(m1_logit)
summary(m1_logit)
m1_logit[[1]]
m1_logit[[2]]
m1_logit[[2]]$ME.all
m1_logit
library(pglm)
library(readstata13)
library(lmtest)
library(MASS)
ships<-readstata13::read.dta13("http://www.stata-press.com/data/r13/ships.dta")
ships$lnservice=log(ships$service)
res <- glm(accident ~ op_75_79+co_65_69+co_70_74+co_75_79+lnservice,family = poisson, data = ships)
res1 <- pglm(accident ~ op_75_79+co_65_69+co_70_74+co_75_79+lnservice,family = poisson, data = ships, effect = "individual", model="within", index = "ship")
coeftest(res) %>% kable()
n1<-coeftest(res)
as.table(n1)
library(foreign)
mydata = read.dta("http://dss.princeton.edu/training/Panel101.dta")
mydata$y <- mydata$y/1000000000
# First, let's create a post time variable
mydata$time = ifelse(mydata$year >= 1994, 1, 0)
# Second, let's create a treated group
mydata$treated = ifelse(mydata$country == "E" |
mydata$country == "F" |
mydata$country == "G", 1, 0)
# Third, the interaction term
mydata$did = mydata$time * mydata$treated
```
View(mydata)
View(mydata)
library(plm) #panel linear model
library(lfe) #linear fixed effect model
library(fixest)
library(ggplot2)
reg6 <- feols(y~ i(treated,year,1994)|country + year, data = mydata)
coefplot(reg6)
library(ggplot2)
reg6 <- feols(y~ i(year,treated,1994)|country + year, data = mydata)
coefplot(reg6)
library(haven)
library(did)
updatedata <- read_dta("C:/Users/jmfern02.AD/Desktop/mortality 1990_1999/updatedata.dta")
updatedata$lnsuiciderate<-log(updatedata$rate_totalsucides)
updatedata$treat <- ifelse(is.na(updatedata$pillmill_date), 0, 1)
updatedata$pillmill_date[is.na(updatedata$pillmill_date)]<-0
update2<-updatedata[complete.cases(updatedata$Pill_mill), ]
update2$time_to_treat <- ifelse(update2$pillmill_date>0,update2$year-update2$pillmill_date,0)
mod_twfe = feols(rate_totalsucides ~ i(time_to_treat, treat, ref = -1) | fips + year, cluster = ~fips, data = update2 )
iplot(mod_twfe,
xlab = 'Time to treatment',
main = 'Event study: Staggered treatment (TWFE)')
update2$yeartreated<- ifelse(update2$treat==0,10000,update2$pillmill_date)
mod_sa = feols(rate_totalsucides ~ sunab(yeartreated, year) | fips + year, cluster = ~fips, data = update2 )
iplot(list(mod_twfe, mod_sa), ref.line = -1,
xlab = 'Time to treatment',
main = 'Event study: Staggered treatment')
total_reg <- att_gt(yname = "rate_totalsucides", tname = "year", idname = "fips",gname = "pillmill_date", data = update2, bstrap = TRUE, biters = 3000, clustervars = "fips")
total.simple <- aggte(total_reg, type = "simple", clustervars = "fips", bstrap = TRUE)
total.dynamic <- aggte(total_reg, type = "dynamic", clustervars = "fips", bstrap = TRUE)
summary(total.dynamic)
